{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-02</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-03</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-04</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-05</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Temp\n",
       "0  1981-01-01  20.7\n",
       "1  1981-01-02  17.9\n",
       "2  1981-01-03  18.8\n",
       "3  1981-01-04  14.6\n",
       "4  1981-01-05  15.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset daily-min-temperatures.csv\n",
    "with open(\"daily-min-temperatures.csv\") as f:\n",
    "    temp_df = pd.DataFrame(csv.DictReader(f))\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3650 entries, 0 to 3649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    3650 non-null   object\n",
      " 1   Temp    3650 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 57.2+ KB\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['Date'] = pd.to_datetime(temp_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-27</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-28</th>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-29</th>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-30</th>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-31</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3650 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp\n",
       "Date            \n",
       "1981-01-01  20.7\n",
       "1981-01-02  17.9\n",
       "1981-01-03  18.8\n",
       "1981-01-04  14.6\n",
       "1981-01-05  15.8\n",
       "...          ...\n",
       "1990-12-27  14.0\n",
       "1990-12-28  13.6\n",
       "1990-12-29  13.5\n",
       "1990-12-30  15.7\n",
       "1990-12-31  13.0\n",
       "\n",
       "[3650 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3650 entries, 0 to 3649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    3650 non-null   datetime64[ns]\n",
      " 1   Temp    3650 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 57.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df['Temp'] = pd.to_numeric(temp_df.Temp)\n",
    "temp_df.info()\n",
    "type(temp_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity test with ADF\n",
    "The Augmented Dickey-Fuller (ADF) test is a statistical test used to determine whether a given time series is stationary or not. In statistics and econometrics, stationarity is an important concept when analyzing time series data. A stationary time series is one whose statistical properties, such as mean, variance, and autocorrelation, do not change over time.\n",
    "\n",
    "The ADF test is used to check for the presence of a unit root in a time series, which is a root of the characteristic equation for the autoregressive (AR) process that makes the time series non-stationary. In simpler terms, a unit root indicates that the time series is non-stationary.\n",
    "\n",
    "Here's how the ADF test works and when it is used:\n",
    "\n",
    "1. **Null Hypothesis (H0)**: The null hypothesis of the ADF test is that the time series has a unit root, meaning it is non-stationary. In other words, the null hypothesis assumes that the time series has a unit root and is not stationary.\n",
    "\n",
    "2. **Alternative Hypothesis (H1)**: The alternative hypothesis is that the time series is stationary; it does not have a unit root.\n",
    "\n",
    "3. **Test Statistic**: The ADF test computes a test statistic, which is essentially a t-statistic, and its value is compared to critical values from a specific distribution.\n",
    "\n",
    "4. **Critical Values**: The critical values are used to determine the significance of the test statistic. If the test statistic is less than the critical value, you can reject the null hypothesis in favor of the alternative, indicating that the time series is stationary.\n",
    "\n",
    "5. **Interpretation**: If the ADF test statistic is less than the critical value, you can conclude that the time series is stationary. If the test statistic is greater than the critical value, you fail to reject the null hypothesis, indicating that the time series is non-stationary.\n",
    "\n",
    "The ADF test is commonly used in time series analysis, especially in financial and economic forecasting, to assess whether a particular financial or economic time series is stationary. Stationarity is important because many time series forecasting methods, like ARIMA (AutoRegressive Integrated Moving Average), assume that the data is stationary. If the data is non-stationary, it might need differencing or other transformations to make it suitable for modeling.\n",
    "\n",
    "In summary, the ADF test is a statistical test used to check for stationarity in time series data by assessing the presence of a unit root. It is a valuable tool in time series analysis and helps in choosing appropriate models for forecasting and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -4.444805\n",
      "p-value: 0.000247\n",
      "Critical Values:\n",
      "\t1%: -3.432\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(temp_df.Temp.values)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary. The more negative this statistic, the more likely we are to reject the null hypothesis.\n",
    "As part of the output, we get a look-up table to help determine the ADF statistic. We can see that our statistic value of -4 is less than the value of -3.449 at 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-step sarima forecast\n",
    "def sarima_forecast2(history, config):\n",
    "    order, sorder, trend, exog_raw = config\n",
    "\n",
    "    try:\n",
    "       # define model\n",
    "        model = SARIMAX(history, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        # fit model\n",
    "        model_fit = model.fit(disp=False)\n",
    "        # make one step forecast, start and end are the same\n",
    "        #yhat = model_fit.predict(start=len(history), end=len(history), exog=exog_raw[len(history),:])\n",
    "        pre = model_fit.get_prediction(start=len(history), end=len(history))\n",
    "        yhat = pre.predicted_mean\n",
    "        yhat_ci = pre.conf_int(alpha=0.5)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"No prediction\")\n",
    "        print(\"Length: \"+str(len(history)))\n",
    "        yhat = [0] # no prediction\n",
    "        yhat_ci = [0]\n",
    "        model = None\n",
    "        model_fit = None\n",
    "    return yhat[0], yhat_ci, model, model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "# n_test: number of time steps to use in the test set\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predictions for univariate data\n",
    "def walk_forward_validation2(data, n_test, cfg):\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions = list()\n",
    "    predictions_lci = list()\n",
    "    predictions_hci = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat, yhat_ci, model, results = sarima_forecast2(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        predictions_lci.append(yhat_ci[:,0])\n",
    "        predictions_hci.append(yhat_ci[:,1])\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    #error = measure_rmse(test, predictions)\n",
    "    predictions_df[\"PRED\"] = predictions\n",
    "    predictions_df[\"PRED_LCI\"] = predictions_lci\n",
    "    predictions_df[\"PRED_HCI\"] = predictions_hci\n",
    "    return [test, predictions_df, model, results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(data, n_test, cfg):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    order, sorder, trend, exog_data = cfg\n",
    "\n",
    "    key = str(order)+', '+str(sorder)+', '+str(trend)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    # one failure during model validation suggests an unstable config\n",
    "    try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "        with catch_warnings():\n",
    "            filterwarnings(\"ignore\")\n",
    "            test, predictions_df, model, results = walk_forward_validation2(data, n_test, cfg)\n",
    "            result = measure_rmse(test, predictions_df['PRED'])    \n",
    "    except:\n",
    "        result = None\n",
    "    # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        try:\n",
    "            #  Parallel object with the number of cores to use and set it to the number of scores detected in your hardware\n",
    "            executor = Parallel(n_jobs=cpu_count()-1, backend='multiprocessing', verbose=10)\n",
    "            tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "            scores = executor(tasks)\n",
    "        except:\n",
    "            scores = [None]\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of sarima configs to try\n",
    "# no seasonal component by default, we need to have more than one years data for that\n",
    "def sarima_configs(seasonal=[0], exog_data=None):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    p_params = [0, 1, 2]\n",
    "    d_params = [1]\n",
    "    q_params = [0, 1, 2]\n",
    "    t_params = ['n','c','t','ct']\n",
    "    P_params = [0]\n",
    "    D_params = [0]\n",
    "    Q_params = [0]\n",
    "    m_params = seasonal\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t, exog_data]\n",
    "                                    models.append(cfg)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 72models\n",
      " > Model[(0, 0, 0), (0, 0, 0, 0), n] 10.891\n",
      " > Model[(0, 0, 0), (0, 0, 0, 0), c] 3.533\n",
      " > Model[(0, 0, 0), (0, 0, 0, 0), t] 7.348\n",
      " > Model[(0, 0, 0), (0, 0, 0, 0), ct] 3.584\n",
      " > Model[(0, 0, 1), (0, 0, 0, 0), n] 6.345\n",
      " > Model[(0, 0, 1), (0, 0, 0, 0), c] 2.757\n",
      " > Model[(0, 0, 1), (0, 0, 0, 0), t] 4.638\n",
      " > Model[(0, 0, 1), (0, 0, 0, 0), ct] 2.787\n",
      " > Model[(0, 0, 2), (0, 0, 0, 0), n] 4.732\n",
      " > Model[(0, 0, 2), (0, 0, 0, 0), c] 2.585\n",
      " > Model[(0, 0, 2), (0, 0, 0, 0), t] 3.736\n",
      " > Model[(0, 0, 2), (0, 0, 0, 0), ct] 2.606\n",
      " > Model[(0, 1, 0), (0, 0, 0, 0), n] 2.673\n",
      " > Model[(0, 1, 0), (0, 0, 0, 0), c] 2.673\n",
      " > Model[(0, 1, 0), (0, 0, 0, 0), t] 2.674\n",
      " > Model[(0, 1, 0), (0, 0, 0, 0), ct] 2.674\n",
      " > Model[(0, 1, 1), (0, 0, 0, 0), n] 2.558\n",
      " > Model[(0, 1, 1), (0, 0, 0, 0), c] 2.559\n",
      " > Model[(0, 1, 1), (0, 0, 0, 0), t] 2.598\n",
      " > Model[(0, 1, 1), (0, 0, 0, 0), ct] 2.599\n",
      " > Model[(0, 1, 2), (0, 0, 0, 0), n] 2.320\n",
      " > Model[(0, 1, 2), (0, 0, 0, 0), c] 2.321\n",
      " > Model[(0, 1, 2), (0, 0, 0, 0), t] 2.375\n",
      " > Model[(0, 1, 2), (0, 0, 0, 0), ct] 2.376\n"
     ]
    }
   ],
   "source": [
    "# main program\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    data = temp_df['Temp'].values\n",
    "    # data split (we have more than 3000 days)\n",
    "    n_test = 265\n",
    "    # model configs\n",
    "    # To add seasonality of one year, we add 365, because we have daily data\n",
    "    #cfg_list = sarima_configs(seasonal=[0, 12]) <- if we have monthly data\n",
    "    cfg_list = sarima_configs(seasonal=[0],exog_data=None)\n",
    "    print(\"Testing \" + str(len(cfg_list)) + \"models\")\n",
    "    # grid search\n",
    "    scores = grid_search(data, cfg_list, n_test, parallel=False)\n",
    "    #scores = grid_search(data, cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the final model (this can take some minutes depending on the hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3649\n",
      "Model:               SARIMAX(3, 1, 1)   Log Likelihood               -8376.942\n",
      "Date:                Sat, 16 May 2020   AIC                          16763.884\n",
      "Time:                        18:19:04   BIC                          16794.890\n",
      "Sample:                             0   HQIC                         16774.927\n",
      "                               - 3649                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.4964      0.019     26.212      0.000       0.459       0.534\n",
      "ar.L2         -0.1304      0.018     -7.096      0.000      -0.166      -0.094\n",
      "ar.L3       5.042e-05      0.018      0.003      0.998      -0.036       0.036\n",
      "ma.L1         -0.9005      0.011    -82.448      0.000      -0.922      -0.879\n",
      "sigma2         5.8021      0.128     45.184      0.000       5.550       6.054\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       45.89   Jarque-Bera (JB):                14.28\n",
      "Prob(Q):                              0.24   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.86   Skew:                             0.08\n",
      "Prob(H) (two-sided):                  0.01   Kurtosis:                         3.27\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "data =  temp_df['Temp'].values\n",
    "# data split\n",
    "n_test = 265\n",
    "# winning parameters\n",
    "cfg = [(3,1,1), (0,0,0,0), 'n', None]\n",
    "test, preds_df, md, results = walk_forward_validation2(data=data, n_test=n_test, cfg=cfg)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "results.save('AUSTemp_SARIMA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
